@article{Voelkl2018,
abstract = {Single-laboratory studies conducted under highly standardized conditions are the gold standard in preclinical animal research. Using simulations based on 440 preclinical studies across 13 different interventions in animal models of stroke, myocardial infarction, and breast cancer, we compared the accuracy of effect size estimates between single-laboratory and multi-laboratory study designs. Single-laboratory studies generally failed to predict effect size accurately, and larger sample sizes rendered effect size estimates even less accurate. By contrast, multi-laboratory designs including as few as 2 to 4 laboratories increased coverage probability by up to 42 percentage points without a need for larger sample sizes. These findings demonstrate that within-study standardization is a major cause of poor reproducibility. More representative study samples are required to improve the external validity and reproducibility of preclinical animal research and to prevent wasting animals and resources for inconclusive research.},
author = {Voelkl, Bernhard and Vogt, Lucile and Sena, Emily S. and W{\"{u}}rbel, Hanno},
doi = {10.1371/journal.pbio.2003693},
isbn = {1111111111},
issn = {15457885},
journal = {PLoS Biology},
number = {2},
pmid = {29470495},
title = {{Reproducibility of preclinical animal research improves with heterogeneity of study samples}},
volume = {16},
year = {2018}
}
@article{OHare2015,
abstract = {Model parameter inference has become increasingly popular in recent years in the field of computational epidemiology, especially for models with a large number of parameters. Techniques such as Approximate Bayesian Computation (ABC) or maximum/partial likelihoods are commonly used to infer parameters in phenomenological models that best describe some set of data. These techniques rely on efficient exploration of the underlying parameter space, which is difficult in high dimensions, especially if there are correlations between the parameters in the model that may not be known a priori. The aim of this article is to demonstrate the use of the recently invented Adaptive Metropolis algorithm for exploring parameter space in a practical way through the use of a simple epidemiological model.},
author = {O'Hare, Anthony},
doi = {10.1089/cmb.2015.0086},
issn = {1066-5277},
journal = {Journal of Computational Biology},
keywords = {1999,also,antigen,bola,bola-drb3,bovine,called the bovine leucocyte,complex,genotyping,includes many immune-related genes,lewin et al,mhc,of cattle,the major histocompatibility complex},
number = {11},
pages = {997--1004},
pmid = {26176624},
title = {{Inference in High-Dimensional Parameter Space}},
url = {http://online.liebertpub.com/doi/10.1089/cmb.2015.0086},
volume = {22},
year = {2015}
}
@article{Cozzo2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1311.1759v4},
author = {Cozzo, Emanuele and Moreno, Yamir},
eprint = {arXiv:1311.1759v4},
file = {:home/melian/Downloads/1311.1759.pdf:pdf},
title = {{Dimensionality reduction and spectral properties of multilayer networks}},
year = {2018}
}
@book{MarkowitzBook,
author = {Markowitz, H},
publisher = {Blackwell Publishing, MA},
title = {{Portfolio selection}},
year = {1991}
}
@article{Walters2011,
abstract = {In this paper we survey the literature on the Black-Litterman model. This survey is provided both as a chronology and a taxonomy as there are many claims on the model in the literature. We provide a complete description of the canonical model including full derivations from the underlying principles using both Theil's Mixed Estimation model and Bayes Theory. The various parameters of the model are considered, along with information on their computation or calibration. Further consideration is given to several of the key papers, with worked examples illustrating the concepts.},
author = {Walters, Jay},
doi = {10.2139/ssrn.1314585},
isbn = {1556-5068},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
title = {{The Black-Litterman Model in Detail}},
url = {http://www.ssrn.com/abstract=1314585},
year = {2011}
}
@article{Gaoetal:2012,
author = {{Gao J.} and {Buldyrev S. V.} and {Stanley H. E.} and Havlin, S},
journal = {Nature physics},
pages = {40--48},
title = {{Networks formed from interdependent networks}},
volume = {8},
year = {2012}
}
@article{Tarantola:2006,
author = {Tarantola, A},
journal = {Nature physics},
pages = {492--494},
title = {{Popper, {\{}B{\}}ayes and the inverse problem}},
volume = {2},
year = {2006}
}
@article{Grelaudetal:2009,
author = {{Grelaud A.} and {Robert C. P.} and {Marin J-M.} and {Rodolphe F.} and Taly, J-F.},
journal = {Bayesian Analysis},
pages = {317--336},
title = {{{\{}ABC{\}} likelihood-free methods for model choice in {\{}G{\}}ibbs random fields}},
volume = {4},
year = {2009}
}
@article{Kivela:2013,
author = {Kivela, M},
journal = {http://www.plexmath.eu/?page{\_}id=327},
title = {{Multilayer networks library}},
year = {2013}
}
@article{Ioannidis2005,
abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
author = {Ioannidis, J. P. A.},
doi = {10.1371/journal.pmed.0020124},
issn = {1549-1676},
journal = {PLoS medicine},
keywords = {Bias (Epidemiology),Data Interpretation,Likelihood Functions,Meta-Analysis as Topic,Odds Ratio,Publishing,Reproducibility of Results,Research Design,Sample Size,Statistical},
month = {aug},
number = {8},
pages = {e124},
pmid = {16060722},
title = {{Why most published research findings are false.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16060722},
volume = {2},
year = {2005}
}
@article{DeDomenico:2014,
author = {{De Domenico M.} and {Porter M. A.} and Arenas, A},
journal = {Journal of Complex Networks},
pages = {159--176},
title = {{MuxViz: a tool for multilayer analysis and visualization of networks}},
volume = {3},
year = {2014}
}
@unpublished{Bailey2013,
abstract = {We prove that high simulated performance is easily achievable after backtesting a relatively small number of alternative strategy configurations, a practice we denote “backtest overfitting”. The higher the number of configurations tried, the greater is the probability that the backtest is overfit. Because most financial analysts and academics rarely report the number of configurations tried for a given backtest, investors cannot evaluate the degree of overfitting in most investment proposals. The implication is that investors can be easily misled into allocating capital to strategies that appear to be mathematically sound and empirically supported by an outstanding backtest. Under memory effects, backtest overfitting leads to negative expected returns out-of-sample, rather than zero performance. This may be one of several reasons why so many quantitative funds appear to fail.},
author = {Bailey, David H. and Borwein, Jonathan and {Lopez de Prado}, Marcos and Zhu, Qiji Jim},
booktitle = {SSRN},
doi = {10.2139/ssrn.2308659},
issn = {0002-9920},
keywords = {E44,G0,G1,G15,G2,G24,Sharpe ratio,backtest,historical simulation,investment strategy,minimum backtest length,optimization,performance degradation,probability of backtest over-fitting},
title = {{Pseudo-Mathematics and Financial Charlatanism: The Effects of Backtest Overfitting on Out-of-Sample Performance}},
year = {2013}
}
@article{Kivelaetal:2014,
author = {{Kivela M.} and {Arenas A.} and {Barthelemy M.} and {Gleeson J. P.} and {Moreno Y.} and Porter, M A},
journal = {Journal of Complex Networks},
pages = {203--271},
title = {{Multilayer networks}},
volume = {3},
year = {2014}
}
@article{Cristian1989,
abstract = {Abstract A probabilistic method is proposed for reading remote clocks in distributed systems subject to unbounded random communication delays. The method can achieve clock synchronization precisions superior to those attainable by previously published clock ... $\backslash$n},
author = {Cristian, Flaviu},
doi = {10.1007/BF01784024},
issn = {01782770},
journal = {Distributed Computing},
keywords = {Clock synchronization,Communication,Distributed system,Fault-tolerance,Time service},
number = {3},
pages = {146--158},
title = {{Probabilistic clock synchronization}},
volume = {3},
year = {1989}
}
@article{Beaumont:2010,
author = {Beaumont, M A},
journal = {Annual Review Ecology, Evolution and Systematics},
pages = {379--406},
title = {{Approximate {\{}B{\}}ayesian Computation in Evolution and Ecology}},
volume = {41},
year = {2010}
}
@article{DeDomenicoetal:2015,
author = {{De Domenico M.} and {Nicosia V.} and Latora, V},
journal = {Nature Communications},
pages = {6864},
title = {{Structural reducibility of multilayer networks}},
volume = {6},
year = {2015}
}
@article{Vats2015,
abstract = {Markov chain Monte Carlo (MCMC) produces a correlated sample for estimating expectations with respect to a target distribution. A fundamental question is when should sampling stop so that we have good estimates of the desired quantities? The key to answering this question lies in assessing the Monte Carlo error through a multivariate Markov chain central limit theorem (CLT). The multivariate nature of this Monte Carlo error largely has been ignored in the MCMC literature. We present a multivariate framework for terminating simulation in MCMC. We define a multivariate effective sample size, estimating which requires strongly consistent estimators of the covariance matrix in the Markov chain CLT; a property we show for the multivariate batch means estimator. We then provide a lower bound on the number of minimum effective samples required for a desired level of precision. This lower bound depends on the problem only in the dimension of the expectation being estimated, and not on the underlying stochastic process. This result is obtained by drawing a connection between terminating simulation via effective sample size and terminating simulation using a relative standard deviation fixed-volume sequential stopping rule; which we demonstrate is an asymptotically valid procedure. The finite sample properties of the proposed method are demonstrated in a variety of examples.},
archivePrefix = {arXiv},
arxivId = {1512.07713},
author = {Vats, Dootika and Flegal, James M. and Jones, Galin L.},
doi = {10.1016/j.jaad.2011.01.035},
eprint = {1512.07713},
file = {::},
isbn = {1512.07713},
issn = {0190-9622},
title = {{Multivariate Output Analysis for Markov chain Monte Carlo}},
url = {http://arxiv.org/abs/1512.07713},
year = {2015}
}
