Robhoot aims to connect scientists and the public (Administration, NGOs, etc) to interact in a decentralized open-access
knowledge network to gain informed decisions when solving complex social, environmental and technological problems. Current technologies for scientific inquiry are highly
fragmented and thus only increase robustness, reproducibility and the interactions with the public marginally. The goal of Robhoot is to propose a new hybrid-
technology concept combining deep learning, automation and distributed ledger technology with the advances of neural biological networks to lay the foundation for a novel open-
science ecosystem aiming to couple predictive and knowledge power in knowledge-inspired societies. Robhoot is not set out to deliver a finished deep knowledge ledger
network in the science ecosystem but provide a science-enabled technology in establishing a prototype proof-of-principle for an open public-science ecosystem.

Data come from many sources. Yet, inferring insightful patterns and drivers integrating datasets remains challenging. 
Robhoot aims to develop approaches to integrate data, statistical Learning, AI algorithms and process-based models to take better informed decisions when solving complex social, environmental and technological problems. Robhoot will automate algorithms to explore the robustness of the scientific process integrating the following layers:


## 1. Data Collection (DC)

Algorithms will collect, clean and integrate data received from many sources. The interated data will be available in CSV, mysql, or "real time data" (e.g. integrating Clickhouse or GraphQL). Robhoot v.1.0.0 aims to have a funcitonal package in Julia to let the user automatically get the integrated data in their desired format. The package for data collection and integration will contain different algorithms to do the job.

## 2. Complexity Reduction (CR)

Robhoot will reduce data dimensionality using a variety of model complexity reduction methods. Robhoot will combine classical PCA, correlation methods and information theory metrics in multilayer networks to contrast the robutness of data complexity reduction.

## 3. Pattern Process Inference (PPI)

Many patterns can be extracted from data. Robhoot will combine classic variance-covariance matrix methods with AI, machine learning, and process-based stochastic and deterministic modeling to understand the processes underlying the patterns.

## 4. Model Validation (MV)

We will use different model selection criteria accounting for uncertainty in the parameter estimations using information theory methods, Bayesian Inference and Approximate Bayesian Computation methods. 

## 5. Visualization (VI)

We will use plotting and visualization tools (e.g., [Plotly](https://plot.ly/), [JoVE](https://www.jove.com/visualize)) for the empirical patterns and the models that best predict the empirical patterns. We will summarize the patterns and processes in compact and clean animation tools to help to improve the multilayer protocol and in making decisions in research, management and investment landscapes.

## 6. Reporting generation (REG)

Robhoot will produce report accounting for the population of explored paths (i.e., each path connects the different layers).  
