# Robhoot Vision

High-resolution data come from many sources. Yet, inferring insightful patterns and drivers remains challenging in many disciplines. Robhoot aims to develop approaches to integrate data, statistical Learning, AI algorithms and process-based models to take better informed decisions in research, management and investment landscapes.

We process and analyze the data in different layers. Within each layer there are different methods that can complete the task. Ideally, one should be able to choose any method from each layer.

## Data processing layers

### 1. Data Collection (DC)

We collect and clean data received from many sources. The collected data can be available in CSV, mysql, or "real time data" (e.g. [Nakamoto Terminal](https://www.nterminal.com), [BigQuery]( https://cloud.google.com/bigquery/)). We aim to have a package in Julia to let the user automatically get the data in their desired format.

## 2. Complexity Reduction (CR)

To increase performance, we will reduce data dimensionality using a variety of model complexity reduction methods from PCA and correlation patterns in multilayer networks to information theory metrics.

## 3. Pattern Inference (PI)

Many patterns can be extracted from high-dimensionality data. We aim to combine classic variance-covariance matrix methods with AI, machine learning and process-based modeling to critically evaluate the robustness of the patterns.

## 4. Model Validation (MV)

We aim to infer patterns and processes combining Information theory methods, Bayesian Inference and Approximate Bayesian Computation methods.

## 5. Visualization (VI)

We will use plotting and visualization tools (e.g., [Plotly](https://plot.ly/), []JoVE](https://www.jove.com/visualize) for the metrics and models that best predict the empirical patterns. 


More soon!
