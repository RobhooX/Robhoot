@article{Voelkl2018,
abstract = {Single-laboratory studies conducted under highly standardized conditions are the gold standard in preclinical animal research. Using simulations based on 440 preclinical studies across 13 different interventions in animal models of stroke, myocardial infarction, and breast cancer, we compared the accuracy of effect size estimates between single-laboratory and multi-laboratory study designs. Single-laboratory studies generally failed to predict effect size accurately, and larger sample sizes rendered effect size estimates even less accurate. By contrast, multi-laboratory designs including as few as 2 to 4 laboratories increased coverage probability by up to 42 percentage points without a need for larger sample sizes. These findings demonstrate that within-study standardization is a major cause of poor reproducibility. More representative study samples are required to improve the external validity and reproducibility of preclinical animal research and to prevent wasting animals and resources for inconclusive research.},
author = {Voelkl, Bernhard and Vogt, Lucile and Sena, Emily S. and W{\"{u}}rbel, Hanno},
doi = {10.1371/journal.pbio.2003693},
isbn = {1111111111},
issn = {15457885},
journal = {PLoS Biology},
number = {2},
pmid = {29470495},
title = {{Reproducibility of preclinical animal research improves with heterogeneity of study samples}},
volume = {16},
year = {2018}
}
@article{OHare2015,
abstract = {Model parameter inference has become increasingly popular in recent years in the field of computational epidemiology, especially for models with a large number of parameters. Techniques such as Approximate Bayesian Computation (ABC) or maximum/partial likelihoods are commonly used to infer parameters in phenomenological models that best describe some set of data. These techniques rely on efficient exploration of the underlying parameter space, which is difficult in high dimensions, especially if there are correlations between the parameters in the model that may not be known a priori. The aim of this article is to demonstrate the use of the recently invented Adaptive Metropolis algorithm for exploring parameter space in a practical way through the use of a simple epidemiological model.},
author = {O'Hare, Anthony},
doi = {10.1089/cmb.2015.0086},
issn = {1066-5277},
journal = {Journal of Computational Biology},
keywords = {1999,also,antigen,bola,bola-drb3,bovine,called the bovine leucocyte,complex,genotyping,includes many immune-related genes,lewin et al,mhc,of cattle,the major histocompatibility complex},
number = {11},
pages = {997--1004},
pmid = {26176624},
title = {{Inference in High-Dimensional Parameter Space}},
url = {http://online.liebertpub.com/doi/10.1089/cmb.2015.0086},
volume = {22},
year = {2015}
}

@Article{       Melo&Marroig:2014,
  author	= {Melo, D., and Marroig, G.},
  year		= 2014,
  title		= {Directional selection can drive the evolution of modularity in complex traits},
  journal	= {Proceedings of the National Academy of the Sciences, USA.},
  volume	= 112,
  pages		= {470-475},
  pozn		= {neni},
  kod		= {}
}

@Article{     Schmidhuber:2015,
  author	= {Schmidhuber, J.},
  year		= 2015,
  title		= {Deep learning in neural networks: An overview},
  journal	= {Neural Networks},
  volume	= 61,
  pages		= {85-117},
  pozn		= {},
  kod		= {}
}

@Article{     Lande:1980,
  author	= {Lande, R.},
  year		= 1980,
  title		= {The genetic covariance between characters maintained by pleiotropic mutations},
  journal	= {Genetics},
  volume	= 94,
  pages		= {203-215},
  pozn		= {},
  kod		= {}
}

@Article{     Ghahramani:2015,
  author	= {Ghaharmani, Z.},
  year		= 2015,
  title		= {Probabilistic machine learning and artificial intelligence},
  journal	= {Nature},
  volume	= 521,
  pages		= {452-459},
  pozn		= {},
  kod		= {}
}

@Article{     Sheehan&Song:2016,
  author	= {Sheehan, S., and Song, Y. S.},
  year		= 2016,
  title		= {Deep learning for population genetic inference},
  journal	= {PLoS Comput. Biol.},
  volume	= 12:,
  pages		= {e10048452},
  pozn		= {},
  kod		= {}
}


@Article{Reichsteietal2019,
abstract = {Machine learning approaches are increasingly used to extract patterns and insights from the ever-increasing stream of geospatial data, but current approaches may not be optimal when system behaviour is dominated by spatial or temporal context. Here, rather than amending classical machine learning, we argue that these contextual cues should be used as part of deep learning (an approach that is able to extract spatio-temporal features automatically) to gain further process understanding of Earth system science problems, improving the predictive ability of seasonal forecasting and modelling of long-range spatial connections across multiple timescales, for example. The next step will be a hybrid modelling approach, coupling physical process models with the versatility of data-driven machine learning.},
author = {Reichstein, M. and Camps-Valls, G. and Stevens, B. and Jung, M. and Denzler, J. and Carvalhais, N. and Prabhat},
doi = {10.1038/s41586-019-0912-1},
journal = {Nature},
pages = {195--2024},
title = { Deep learning and process understanding for data-driven Earth system science},
volume = {566},
year = {2019}
}

@Article{     Melianetal:2018,
  author	= {Meli\'an, C. J. and Matthews, B. and Andreazzi, C. S. and
  Rodr\'iguez, J. P. and Harmon, L. J. and Fortuna, M. A.},
  year		= 2018,
  title		= {Deciphering the interdependence between ecological and evolutionary networks},
  journal	= {Trends in Ecology and Evolution},
  volume	= 33,
  pages		= {504-512},
  pozn		= {},
  kod		= {}
}

@article{Cozzo2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1311.1759v4},
author = {Cozzo, Emanuele and Moreno, Yamir},
eprint = {arXiv:1311.1759v4},
file = {:home/melian/Downloads/1311.1759.pdf:pdf},
title = {{Dimensionality reduction and spectral properties of multilayer networks}},
year = {2018}
}
@book{MarkowitzBook,
author = {Markowitz, H},
publisher = {Blackwell Publishing, MA},
title = {{Portfolio selection}},
year = {1991}
}
@article{Walters2011,
abstract = {In this paper we survey the literature on the Black-Litterman model. This survey is provided both as a chronology and a taxonomy as there are many claims on the model in the literature. We provide a complete description of the canonical model including full derivations from the underlying principles using both Theil's Mixed Estimation model and Bayes Theory. The various parameters of the model are considered, along with information on their computation or calibration. Further consideration is given to several of the key papers, with worked examples illustrating the concepts.},
author = {Walters, Jay},
doi = {10.2139/ssrn.1314585},
isbn = {1556-5068},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
title = {{The Black-Litterman Model in Detail}},
url = {http://www.ssrn.com/abstract=1314585},
year = {2011}
}
@article{Gaoetal:2012,
author = {{Gao J.} and {Buldyrev S. V.} and {Stanley H. E.} and Havlin, S},
journal = {Nature physics},
pages = {40--48},
title = {{Networks formed from interdependent networks}},
volume = {8},
year = {2012}
}
@article{Tarantola:2006,
author = {Tarantola, A},
journal = {Nature physics},
pages = {492--494},
title = {{Popper, {\{}B{\}}ayes and the inverse problem}},
volume = {2},
year = {2006}
}
@article{Grelaudetal:2009,
author = {{Grelaud A.} and {Robert C. P.} and {Marin J-M.} and {Rodolphe F.} and Taly, J-F.},
journal = {Bayesian Analysis},
pages = {317--336},
title = {{{\{}ABC{\}} likelihood-free methods for model choice in {\{}G{\}}ibbs random fields}},
volume = {4},
year = {2009}
}
@article{Kivela:2013,
author = {Kivela, M},
journal = {http://www.plexmath.eu/?page{\_}id=327},
title = {{Multilayer networks library}},
year = {2013}
}
@article{Ioannidis2005,
abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
author = {Ioannidis, J. P. A.},
doi = {10.1371/journal.pmed.0020124},
issn = {1549-1676},
journal = {PLoS medicine},
keywords = {Bias (Epidemiology),Data Interpretation,Likelihood Functions,Meta-Analysis as Topic,Odds Ratio,Publishing,Reproducibility of Results,Research Design,Sample Size,Statistical},
month = {aug},
number = {8},
pages = {e124},
pmid = {16060722},
title = {{Why most published research findings are false.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16060722},
volume = {2},
year = {2005}
}
@article{DeDomenico:2014,
author = {{De Domenico M.} and {Porter M. A.} and Arenas, A},
journal = {Journal of Complex Networks},
pages = {159--176},
title = {{MuxViz: a tool for multilayer analysis and visualization of networks}},
volume = {3},
year = {2014}
}
@unpublished{Bailey2013,
abstract = {We prove that high simulated performance is easily achievable after backtesting a relatively small number of alternative strategy configurations, a practice we denote \93backtest overfitting\94. The higher the number of configurations tried, the greater is the probability that the backtest is overfit. Because most financial analysts and academics rarely report the number of configurations tried for a given backtest, investors cannot evaluate the degree of overfitting in most investment proposals. The implication is that investors can be easily misled into allocating capital to strategies that appear to be mathematically sound and empirically supported by an outstanding backtest. Under memory effects, backtest overfitting leads to negative expected returns out-of-sample, rather than zero performance. This may be one of several reasons why so many quantitative funds appear to fail.},
author = {Bailey, David H. and Borwein, Jonathan and {Lopez de Prado}, Marcos and Zhu, Qiji Jim},
booktitle = {SSRN},
doi = {10.2139/ssrn.2308659},
issn = {0002-9920},
keywords = {E44,G0,G1,G15,G2,G24,Sharpe ratio,backtest,historical simulation,investment strategy,minimum backtest length,optimization,performance degradation,probability of backtest over-fitting},
title = {{Pseudo-Mathematics and Financial Charlatanism: The Effects of Backtest Overfitting on Out-of-Sample Performance}},
year = {2013}
}
@article{Kivelaetal:2014,
author = {{Kivela M.} and {Arenas A.} and {Barthelemy M.} and {Gleeson J. P.} and {Moreno Y.} and Porter, M A},
journal = {Journal of Complex Networks},
pages = {203--271},
title = {{Multilayer networks}},
volume = {3},
year = {2014}
}
@article{Cristian1989,
abstract = {Abstract A probabilistic method is proposed for reading remote clocks in distributed systems subject to unbounded random communication delays. The method can achieve clock synchronization precisions superior to those attainable by previously published clock ... $\backslash$n},
author = {Cristian, Flaviu},
doi = {10.1007/BF01784024},
issn = {01782770},
journal = {Distributed Computing},
keywords = {Clock synchronization,Communication,Distributed system,Fault-tolerance,Time service},
number = {3},
pages = {146--158},
title = {{Probabilistic clock synchronization}},
volume = {3},
year = {1989}
}
@article{Beaumont:2010,
author = {Beaumont, M A},
journal = {Annual Review Ecology, Evolution and Systematics},
pages = {379--406},
title = {{Approximate {\{}B{\}}ayesian Computation in Evolution and Ecology}},
volume = {41},
year = {2010}
}
@article{DeDomenicoetal:2015,
author = {{De Domenico M.} and {Nicosia V.} and Latora, V},
journal = {Nature Communications},
pages = {6864},
title = {{Structural reducibility of multilayer networks}},
volume = {6},
year = {2015}
}
@Article{    Schmidhuber:2015,
  author = {Schmidhuber, J.},
  year = 2015,
  title = {Deep learning in neural networks: An overview},
  journal = {Neural Networks},
  volume = 61,
  pages = {85-117},
  pozn = {},
  kod = {}
}

@article{Vats2015,
abstract = {Markov chain Monte Carlo (MCMC) produces a correlated sample for estimating expectations with respect to a target distribution. A fundamental question is when should sampling stop so that we have good estimates of the desired quantities? The key to answering this question lies in assessing the Monte Carlo error through a multivariate Markov chain central limit theorem (CLT). The multivariate nature of this Monte Carlo error largely has been ignored in the MCMC literature. We present a multivariate framework for terminating simulation in MCMC. We define a multivariate effective sample size, estimating which requires strongly consistent estimators of the covariance matrix in the Markov chain CLT; a property we show for the multivariate batch means estimator. We then provide a lower bound on the number of minimum effective samples required for a desired level of precision. This lower bound depends on the problem only in the dimension of the expectation being estimated, and not on the underlying stochastic process. This result is obtained by drawing a connection between terminating simulation via effective sample size and terminating simulation using a relative standard deviation fixed-volume sequential stopping rule; which we demonstrate is an asymptotically valid procedure. The finite sample properties of the proposed method are demonstrated in a variety of examples.},
archivePrefix = {arXiv},
arxivId = {1512.07713},
author = {Vats, Dootika and Flegal, James M. and Jones, Galin L.},
doi = {10.1016/j.jaad.2011.01.035},
eprint = {1512.07713},
file = {::},
isbn = {1512.07713},
issn = {0190-9622},
title = {{Multivariate Output Analysis for Markov chain Monte Carlo}},
url = {http://arxiv.org/abs/1512.07713},
year = {2015}
}

@article{Mostajabi2019,
author = {Mostajabi, Amirhossein and Finney, Declan L. and Rubinstein, Marcos and Rachidi, Farhad},
doi = {10.1038/s41612-019-0098-0},
issn = {2397-3722},
journal = {npj Climate and Atmospheric Science},
month = {dec},
number = {1},
pages = {41},
publisher = {Springer US},
title = {{Nowcasting lightning occurrence from commonly available meteorological parameters using machine learning techniques}},
url = {http://dx.doi.org/10.1038/s41612-019-0098-0 http://www.nature.com/articles/s41612-019-0098-0},
volume = {2},
year = {2019}
}

@article{Webb2018,
abstract = {A more tolerant immune system could alleviate, or even prevent, autoimmune disorders such as type 1 diabetes and multiple sclerosis, as well as the rejection of transplanted organs. A more tolerant immune system could alleviate, or even prevent, autoimmune disorders such as type 1 diabetes and multiple sclerosis, as well as the rejection of transplanted organs.},
author = {Webb, Sarah},
doi = {10.1038/d41586-018-02174-z},
issn = {0028-0836},
journal = {Nature},
month = {feb},
number = {7693},
pages = {555--557},
title = {{Deep learning for biology}},
url = {http://www.nature.com/doifinder/10.1038/d41586-018-02174-z},
volume = {554},
year = {2018}
}

@article{Heaven2019,
author = {Heaven, Douglas},
doi = {10.1038/d41586-019-03013-5},
issn = {0028-0836},
journal = {Nature},
month = {oct},
number = {7777},
pages = {163--166},
title = {{Why deep-learning AIs are so easy to fool}},
url = {http://www.nature.com/articles/d41586-019-03013-5},
volume = {574},
year = {2019}
}

@article{Mnih2015,
abstract = {The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
doi = {10.1038/nature14236},
issn = {14764687},
journal = {Nature},
number = {7540},
pages = {529--533},
pmid = {25719670},
publisher = {Nature Publishing Group},
title = {{Human-level control through deep reinforcement learning}},
url = {http://dx.doi.org/10.1038/nature14236},
volume = {518},
year = {2015}
}

@article{Silver2016,
abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses \91value networks' to evaluate board positions and \91policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Using this search algorithm, our program AlphaGo achieved a 99.8 {\%} winning rate against other Go programs and beat the human European Go champion Fan Hui by 5 games to 0, a feat thought to be at least a decade away by Go and AI experts alike. Finally, in a dramatic and widely publicised match, AlphaGo defeated Lee Sedol, the top player of the past decade, 4 games to 1. In this talk, I will explain how AlphaGo works, describe our process of evaluation and improvement, and discuss what we can learn about computational intuition and creativity from the way AlphaGo plays.},
author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
doi = {10.1038/nature16961},
file = {:C$\backslash$:/Users/Victor/WORK/PDF/Silver et al. - 2016 - Mastering the game of Go with deep neural networks and tree search.pdf:pdf},
isbn = {9783319462264},
issn = {0028-0836},
journal = {Nature},
mendeley-groups = {AI},
month = {jan},
number = {7587},
pages = {484--489},
pmid = {26819042},
publisher = {Nature Publishing Group},
title = {{Mastering the game of Go with deep neural networks and tree search}},
url = {http://dx.doi.org/10.1038/nature16961 http://www.nature.com/articles/nature16961},
volume = {529},
year = {2016}
}

@article{Poggio2004,
author = {Poggio, Tomaso and Bizzi, Emilio},
doi = {10.1038/nature03014},
file = {:C$\backslash$:/Users/Victor/WORK/PDF/Poggio, Bizzi - 2004 - Generalization in vision and motor control.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
mendeley-groups = {AI},
month = {oct},
number = {7010},
pages = {768--774},
title = {{Generalization in vision and motor control}},
url = {http://www.nature.com/articles/nature03014},
volume = {431},
year = {2004}
}

@incollection{Krizhevsky2012,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

@article{Ferrucci2013,
title = "Watson: Beyond Jeopardy!",
journal = "Artificial Intelligence",
volume = "199-200",
pages = "93 - 105",
year = "2013",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2012.06.009",
url = "http://www.sciencedirect.com/science/article/pii/S0004370212000872",
author = "David Ferrucci and Anthony Levas and Sugato Bagchi and David Gondek and Erik T. Mueller",
abstract = "This paper presents a vision for applying the Watson technology to health care and describes the steps needed to adapt and improve performance in a new domain. Specifically, it elaborates upon a vision for an evidence-based clinical decision support system, based on the DeepQA technology, that affords exploration of a broad range of hypotheses and their associated evidence, as well as uncovers missing information that can be used in mixed-initiative dialog. It describes the research challenges, the adaptation approach, and finally reports results on the first steps we have taken toward this goal."
}
