%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Wenneker Article
% LaTeX Template
% Version 2.0 (28/2/17)
%
% This template was downloaded from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@LaTeXTemplates.com)
% Frits Wenneker
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[10pt, a4paper, twocolumn]{article} % 10pt font size (11 and 12 also possible), A4 paper (letterpaper for US letter) and two column layout (remove for one column)

\usepackage[english]{babel} % English language hyphenation
\usepackage{microtype} % Better typography
\usepackage{amsmath,amsfonts,amsthm} % Math packages for equations
\usepackage[svgnames]{xcolor} % Enabling colors by their 'svgnames'
\usepackage[hang, small, labelfont=bf, up, textfont=it]{caption} % Custom captions under/above tables and figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{lastpage} % Used to determine the number of pages in the document (for "Page X of Total")
\usepackage{graphicx} % Required for adding images
\usepackage{amssymb}
\usepackage[mathscr]{eucal}
\usepackage[table]{xcolor}
\usepackage{enumitem} % Required for customising lists
\setlist{noitemsep} % Remove spacing between bullet/numbered list elements
\usepackage{sectsty} % Enables custom section titles
\allsectionsfont{\usefont{OT1}{phv}{b}{n}} % Change the font of all section commands (Helvetica)
\usepackage{hyperref}
\usepackage[sort,numbers]{natbib}
%----------------------------------------------------------------------------------------
%	MARGINS AND SPACING
%----------------------------------------------------------------------------------------
\usepackage{geometry} % Required for adjusting page dimensions
\geometry{
	top=0.65cm, % Top margin
	bottom=1.5cm, % Bottom margin
	left=1.5cm, % Left margin
	right=1.5cm, % Right margin
	includehead, % Include space for a header
	includefoot, % Include space for a footer
	%showframe, % Uncomment to show how the type block is set on the page
}
\setlength{\columnsep}{6mm} % Column separation width


%----------------------------------------------------------------------------------------
%	FONTS
%----------------------------------------------------------------------------------------

\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage{XCharter} % Use the XCharter font

%\input{structure.tex} % Specifies the document structure and loads requires packages

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------
\begin{document}



\title{$\mathcal{ROBHOOT}$ \\ Open Research Network \\ Whitepaper v.2.0} % The article title
  \author{Universal Neutrality team{\textsuperscript{1,2,3} and XY\textsuperscript{2,3}} % Authors
  \newline\newline % Space before institutions
  \\
	\textsuperscript{1}\institution{}\\ % Institution 1
	\textsuperscript{2}\institution{}\\ % Institution 2
	%\textsuperscript{3}\institution{\texttt{LaTeXTemplates.com}}
      %} % Institution 3


% Example of a one line author/institution relationship
%\author{\newauthor{John Marston} \newinstitution{Universidad Nacional Autónoma de México, Mexico City, Mexico}}

\date{\today} % Add a date here if you would like one to appear underneath the title block, use \today for the current date, leave empty for no date
%---------------------------------------------------------------------------------------

%\begin{document}

\maketitle % Print the title
\thispagestyle{firstpage} % Apply the page style for the first page (no headers and footers)

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------
\lettrineabstract{\section{{\bf Summary}}

  Robhoot fully automates the research cycle in an open decentralized
  network. Research automation with reporting generation will support
  policy making when solving complex social, environmental and
  technological problems. Current technologies for scientific inquiry
  and decision-making will benefit from an increase in robustness,
  reproducibility, open-access and feedback from the public. The goal
  of Robhoot is to develop a hybrid-neutral-technology to lay out the
  foundation for an open-science ecosystem aiming to strengthen the
  robustness, decentralization and reproducibility of science. Robhoot
  is not set out to deliver a finished research open network in the
  science ecosystem, but to provide a science-enabled technology in
  establishing a prototype proof-of-principle to connect automated,
  decentralized and neutral-knowledge generation with
  knowledge-inspired societies.}
%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------
\section{The Science Ecosystem}
Science and technology contain multiple steps of information transfer
among trusted/untrusted peers. As a consequence, the scientific and
technological process end up producing knowledge. Knowledge can be
generated from distinct features. Which are the desirable features of
human-generated knowledge in a open global society? Are features like
openess and reproducibility of knowledge important to reach access to
global science reports to gain informed human-driven decisions in
complex social, environmental and technological problems? Currently
public funded science is highly centralized
\citep{Inhaber1977,Gunther2018}⁠⁠, prone to errors \citep{Fang2011},
difficult to reproduce \citep{Hardwicke2018}, and contains many biases
\citep{Ioannidis2005}. Still, do we need open automated research
networks? Here we aim to provide the minimal design arquitecture of an
automated open research network technology fully accounting for the
research cycle. The goal of such an attempt is to reduce the global
research knowledge gap while accounting for centralization, bias,
error-prone, non-reproducibility and lack of incentives in the
existing science and technology ecosystem (Figure 1 and Table 1).
\includegraphics[width=0.45\textwidth]{flowchart.pdf}

{\small {\bf Figure 1: The architecture of an open automated research
    network technology}. Robhoot targets a reduction of the global
  research knowledge gap (red path) and an increase in reproducibility
  and open global access to system science reports (green path). Open
  automated knowledge generation requires human intervention to be
  minimal while simultaneously accounting for centralization, bias,
  error-prone of the scientific and technological process,
  non-reproducibility, and lack of incentives (red path). To achieve
  such targets, Robhoot will explore open-access automation by
  integrating the following five different technological paradigms:
  First, {\bf Universal ETLs} algorithms (i.e., Extraction,
  Transformation and Load algorithms) to facilitate the integration
  and complexity reduction of multiple-source and heterogeneous
  data. Second, {\bf Bayesian Space Models} accounting for a broad
  exploration of deep-process-based learning networks and optimization
  metrics. Third, {\bf Animation Space} algorithms to broadly
  represent the fitting methods accounting for empirical patterns and
  model predictions. Four, {\bf Reporting} using natural processing
  language algorithms to generate reproducible reports based on
  knowledge graphs, and five, {\bf Distributed algorithms} to
  decentralize knowledge generation making it immutable, open and
  globally accessible.}

Two of the main features of Robhoot are decentralization and
automation. Currently, many studies focusing on decentralized
ecosystems are producing an immense gain of knowledge about
scalability, security and decentralization trade-offs
\citep{Golem2016,Durov2017,Androulaki2018,OceanProtocolFoundation2018,BigchainDBGmbH2018}. Automation
and AI technologies is the other angle from which many advances are
rapidly occurring \citep{Schmidhuber:2015,Reichstein,Gil2019}. Yet,
while the existing technological paradigm is rapidly shifting towards
science-based decentralization and automation technologies, end-to-end
open-source research accounting for decentralized, neutral and
automated knowledge-inspired technologies are missing (Figure 1 and
Table 1) \citep{Gunther2018}. Rapid advances of automated research
platforms facilitating data integration accounting for parts of the
research cycle are currently under development\footnote{This is by no
  means an exhaustive list but it gives an indication of the many
  projects currently in place:
  \href{https://www.nterminal.com}{NakamotoT},\href{https://cloud.google.com/bigquery/}{BigQuery},\href{https://www.automaticstatistician.com/index/}{Automated
    statistician},\href{http://www.modulos.ai/}{Modulos},\href{https://ai.google/}{Google
    AI},\href{https://iris.ai}{Iris},\href{https://github.com/DS3Lab/easeml}{easeml}}
but open-source decentralized and automated networks accounting fully
for the research cycle are still at a very incipient stage of
development. While conceptual frameworks conceptualizing the required
layers in many research fields are well established (Figure 2a), there
is currently a lack of integration, development and automated tools
connecting knowledge graphs (Figure 2b) to deep process-based learning
networks to explore their robustness (Figure 2c) in fully
decentralized ecosystems (Figure 2d).

\begin{table}
 %\rowcolor{pink}
\begin{tabular}{ p{3cm} | p{2cm} | p{2cm}}
  \hline \hline
  \textbf{Features} & \textbf{Science Ecosystem} &\textbf{Robhoot}\\  \hline
  Decentralization & No & Yes \\ \hline
  Full automation & No & Yes \\ \hline
  Open-access & Mostly No & Yes \\ \hline
  Immutability & No & Yes \\ \hline
  Robustness & Mostly No & Yes \\ \hline
  Reproducibility & Mostly No & Yes \\ \hline        
  Owner-Controlled assets & No & Yes \\ \hline       
  \bottomrule

\end{tabular}
\caption{Robhoot aims to be designed to resolve desirable properties
  of science: Decentralization, Automation, Open-access, Immutability,
  Robustness, Reproducibility, and Owner-controlled assets. These
  features will be added during the different stages of the
  development of Robhoot (see section ``Robhoot Design Goals'').}
\end{table}
% ------------------------------------------------
  \section{Robhoot Design Goals}
  Robhoot will be developed in four stages following standard version
  protocols. The most advanced version is to provide real-time
  open-access reporting in a decentralized network to gain informed
  decisions when solving complex social, environmental and
  technological problems. Automating the research cycle in a open
  research network ultimately aims to contrast human-generated science
  with machine-generated science to target
  neutral-knowledge-generation in knowledge-inspired
  societies. Figures 1 to 4 show Robhoot goals and architecture,
  stages, Robhoot in a digital ecosystem and the timeline for each of
  the stages, respectively.
  \includegraphics[width=0.45\textwidth]{Figure1.pdf}

  %\begin{figure*}[ht]
  {\small {\bf Figure 2: Stages of an automated knowledge-based
      network technology}. {\bf a}) {\bf Robhoot 1.0} will account
    fully for the research cycle from data integration (top) to
    reporting generation (bottom). {\bf b}) {\bf Robhoot 2.0} will
    encode each path of the research cycle in {\bf a} as a knowledge
    graph (KG). {\bf c}) {\bf Robhoot 3.0} will add deep
    knowledge-based networks to automatically explore populations of
    KGs to gain robustness of the process-based patterns contained in
    the data. {\bf d}) {\bf Robhoot 4.0} will deploy all KGs in a
    distributed network of mutually trusting/untrusting peers with
    every peer maintaining the population of the KGs.}
  %\end{figure*}
  
  The overall objectives with the tools, methods, and potential
  bottlenecks in each stage for each of the four major Robhoot
  versions are the following: \vspace{-0.15 in}
  \subsection{Robhoot 1.0: Automated Research Cycle}
   \begin{itemize}
   \item {\bf Universal ETLs} will connect generalized algorithms to
     open-source software to extract, transform and load data with
     different properties (i.e., formats, historical-real time,
     storage, dimensions, size, sampling bias and spatiotemporal
     resolution) (Figures 1 and 2a, two top layers).
   \item {\bf Bayesian space models} will explore generalized
     open-ended language of models combining Bayesian networks and
     optimization methods. The Bayesian space models module will
     search, evaluate models, trading-off complexity, fit to data and
     quantify resource usage (Figures 1 and 2a, inference and
     validation layers).
   \item {\bf Animation Space} will connect open-source visualization
     software to the exploration of open-ended models to make the
     whole search transparent, highly visual and reproducible (Figures
     1 and 2a, visualization layer).
   \item {\bf Reporting} will develop a procedure to automatically
     explain the structure of the Bayesian space modeling module. It
     will also communicate the module using visualizations of the
     procedures followed by the Universal ETLs and Bayesian space
     models modules (Figures 1 and 2a, reporting layer).
   \item Robhoot 1.0 testnet will use ``Biodiversity and Global Change
     Research databases'' to explore the robustness of the automated
     research cycle, from the {\bf Universal ETLs} and {\bf Bayesian
       space models} to the {\bf Animation space} and {\bf
       Reporting}.
   \end{itemize}

   \begin{itemize}
   \item {\bf Tools and Methods}: Multilayer networks metrics,
     Bayesian Networks, Julia computing language, Open-source software
     protocols, Gitchain, ETLs software, Kafka, Clickhouse.
 \end{itemize}
 \vspace{-0.15 in}
   
  \subsection{Robhoot 2.0: Knowledge Graphs}
  \begin{itemize}
  \item Implementation of algorithms to reproduce paths of the
    research cycle with Knowledge Graphs (KGs) (Figure 2b).
  \item Robustness and stability exploring a suite of open-source
    lineage client-tracker algorithms.
  \end{itemize}

   \begin{itemize}
   \item {\bf Tools and Methods}: Knowlegde graph algorithms and
     packages (i.e., Renku and others).
 \end{itemize}
  \vspace{-0.15 in}
  
  \subsection{Robhoot 3.0: Deep learning networks}
  \begin{itemize}
  \item Deploy automated deep learning algorithms to sample paths of
    the research cycle to produce populations of Knowledge Graphs
    (KGs) (Figures 2a-c).
  \item Exploration of the robustness of automated research cycle combining
    optimization algorithms and the population of Knowledge Graphs
    (Figure 2c).
  \end{itemize}

 \begin{itemize}
 \item {\bf Tools and Methods}: Multilayer networks, Neural Biological
   Networks, Bayesian Networks, Deep learning networks. Optimization
   algorithms.
 \end{itemize}
  
  \vspace{-0.15 in}
  
  \subsection{Robhoot 4.0: Distributed ledger network}
  \begin{itemize}
  \item Deploy a permissioned-permissionless distributed ledger
    technology to guarantee decentralization, open-access,
    neutral-knowledge-based network and prior
    confidenciality/posterior reproducibility of the KGs populations
    (Figures 2c and 2d).
  \item Exploration of a suite of consensus algorithms and smart
    contracts among trusted-untrusted peer-to-peer interactions to
    infer macroscopic metrics of the open research network (Figure
    2d).
  \item Quantification of metrics to study the
    scalability-security-decentralization trade-offs when storing KGs
    in the research network (Figure 2d).
  \item Testnet case study to explore the interaction between
    consensus protocols and the scalability-security-decentralization
    trade-offs when committing the KGs to the distributed ledger.
  \item Mainnet to cryptographically link each population of KGs to
    previous KGs-ledger to create an historical KGs-ledger chain that
    goes back to the genesis ledger in the open research network. The
    mainnet aims to connect multiple database with real-time
    open-access citizen data science to knowledge-inspired societies.
  \end{itemize}

   \begin{itemize}
   \item {\bf Tools and Methods}: Distributed computing algorithms,
     Blockchain and consensus algorithms, BighainDB,
     Gitchain. Telegram open network, Golem.
 \end{itemize}
  
  \section{Robhoot in Digital Ecosystems}
  The science ecosystem currently lack technologies fully automating
  the research cycle into the open-source digital ecosystem. Despite
  public institutions are demanding more reproducibility and openness
  of the data and the scientific process, and overall a shifting
  towards open and reproducible scientific and engineering landscapes,
  there are not currently open and integrated technologies aiming to
  compactly facilitate and distribute the scientific and engineering
  knowledge in open, reproducible and immutable knowledge networks.
  
  Automating knowledge-generation requires the integration of many
  distinct features. Usually, knowledge-generation comes from
  interactions within- and between-layers of the scientific process
  (Figure 2a). The feedbacks occurring within and among layers in the
  science and technology ecosystem also provide unexpected behaviors
  that are difficult to anticipate. Therefore many feedbacks and
  interactions within- and between-layers are not easy to reproduce if
  not properly accounted for. Robhoot will take advantage of the
  open-source software community to explore how knowledge graphs,
  optimization, automation, and decentralization algorithms can be
  connected to the robustness and reproducibility of the scientific
  process (Figure 1).

  Robhoot aims to be a hybrid-technology accounting for many featurers
  (Table 1). Producing such a multi-feature technology requires
  multidisciplinarity teams making functional contributions for each
  of the Robhoot features while integrating all these features in a
  rapidly evolving digital ecosystem. In this regard, Robhoot aims to
  put together scientists and engineers from data science, computer
  science (i.e., distributed computing, software development), the
  physics of complex systems (i.e., multilayer networks), artificial
  intelligence (i.e., deep learning and automation) and the biology,
  ecology and evolution of social, natural and technological
  ecosystems.

  One way of visualizing the multitrait dimensionality of Robhoot in
  the digital ecosystem is to connect each layer of the scientific
  process (Figure 2a) to the open-source software community required
  to gain functionality of the automated research cycle (Figure
  3). For example, Node 0 (left column, Figure 3) can be the Data
  Integration layer in Figure 2a. This node is connected to seven
  nodes representing open-source ETLs open-source software (i.e.,
  extract, transform, load data, central column, Figure
  3). Connections between Node 0 and nodes 5, 6, 8, 9, 10, 12 and 13
  can be rapidly evolving (i.e., indicated by the different red
  tones of the connections). Indeed, open-source ETLs are rapidly
  evolving towards accounting for many heterogeneous aspects of data
  integration (i.e., formats, historical-real time, storage,
  dimensions, size, bias and spatiotemporal resolution). ETLs can
  also be connected to a gradient of reporting generation (i.e., right
  column, Figure 3) noting reports containing only a subset of the
  interactions of the digital ecosystem network. The network of the
  fully automated research cycle can be one where Nodes 0, 1, 2, 3,
  and 4 represent the different layers of the research cycle (left
  column, Figure 3 and Figure 2a) connected to the open-source
  software of the digital ecosystem (central column, Figure 3) to
  generate full populations of reports (right column, Figure 3).

\includegraphics[width=0.45\textwidth]{FigureRobhoot.pdf}

%\begin{figure*}[ht]
{\small {\bf Figure 3: Robhoot in Digital Ecosystems}: {\bf Left
    column}: {\bf Robhoot 1.0} containing the research cycle
  represented as nodes (i.e., from node 0 to 4: Data integration (0),
  Complexity Reduction (1), Inference (2), Validation (3), and
  Visualization(4)). {\bf Central column}: The research cycle layers
  connected to the open-source software in the digital
  ecosystem. Nodes can for example represent the ETLs open-source
  software required to produce a general data integration accounting
  for many data heterogeneities. {\bf Right column}: Reporting
  gradient connected to the open-source software where each report
  (i.e., represented as a node) is generated only using a subset of
  the research layers and ETLs.}
%\end{figure*}


%\section{How to contribute to Robhoot}

%\section{The Robhoot roadmap}
%The following is a first version of the roadmap, the backbone from
%where a more detailed FET-EU proposal will be generated.

\begin{figure*}[ht]
  \centering
  \includegraphics[width=1\textwidth]{GanttChartWhitePaper.pdf}
  {\small {\bf Figure 4: The Robhoot roadmap}: {\bf Robhoot 1.0}
    working packages {\bf WP1} to {\bf WP4} will take care of the
    development, integration, deployment and testing of an automated
    research cycle (Figure 2a). {\bf Robhoot 2.0} working packages
    {\bf WP5} to {\bf WP7} will integrate the knowledge graphs into
    the research cycle (Figure 2b). {\bf Robhoot 3.0} working packages
    {\bf WP8} to {\bf WP11} will develope, implement and test deep
    process-based learning networks to automatically explore
    populations of KGs to gain understanding of the robustness of the
    process-based mechanisms contained in the data (Figure 2c). {\bf
      Robhoot 4.0} working packages {\bf WP12} to {\bf WP13} will deploy
    all KGs into a distributed network of mutually trusting/untrusting
    peers with every peer maintaining the population of the KGs.}
\end{figure*}


%\newpage
\section{Conclusion}
Science and technology ecosystems are in need of accounting for the
uncertainties, reproducibility and immutability related to the
complexity of the research process. This need is not just for a
specific stage of the research cycle, but from data acquisition and
integration to automated reporting generation because
knowledge-inspired societies and decentralized governance will demand
full research cycle transparency to solve complex social,
environmental and technological problems. This need brings many
challenges to our research proposal because obtaining robust knowledge
from integrating many layers of the research cycle, each containing
its own set of methods and uncertainties, can generate divergent,
fragile and contradictory outcomes.

We will develop a flexible research method focusing step by step in
different stages with varying levels of complexity (i.e., from Robhoot
1.0 to 4.0, Figure 4). Our motivation will be to provide a first
open-access proof of concept of how the technology works: we will
automate reproducible research paths along a multilayer network
(Robhoot 1.0) to sample the KGs (Robhoot 2.0) using different deep
learning algorithms to estimate the uncertainty of the ruled-based
inference obtained by fitting predictions to simulated data (Robhoot
3.0). Accounting for the uncertainties of each of the research stages
when sampling the KGs comes from the many distinct paths within and
across the layers in the research cycle (Figure 2a). Robhoot will test
a variety of consensus algorithms to explore the degree of security,
decentralization and scalability of the ledger knowledge network using
the generated population of KGs (Robhoot 4.0).

Despite our focus will be bias towards the algorithmic robustness
during the four stages of Robhoot development, we will develop a
domain-specific case study, a Robhoot Open Network, to test the
robustness of the rule-based inference obtained by fitting each of the
generated KG to empirical patterns. The high risk associated to
robustly automate the full research cycle for producing immutable open
knowledge will be buffered to a great extend because the existing
digital ecosystem of highly reliable open-source software tools
(Figure 3).

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

%\printbibliography[title={Bibliography}] % Print the bibliography, section title in curly brackets

%\newpage
\bibliographystyle{unsrtnat}
%\bibliographystyle{tree.bst}
\bibliography{Robhoot.bib}

%----------------------------------------------------------------------------------------

\end{document}

\hspace{-0.2 in}\includegraphics[width=0.52\textwidth]{Figure3.pdf}
{\small {\bf Figure 1: Prediction power (top), understanding (middle),
    and prediction-understanding power maps (bottom)}. x-axis
  represents data-based inference (i.e., gradient of AI methods from
  low (left) to high (right) predictive power). y-axis represents
  process-based inference (i.e., gradient of process-based methods
  from low (bottom left) to high (top left) understanding power). The
  gradient of predicting power map (top) shows a hot spot red area in
  the bottom right highlighting the region where AI methods best
  predict the empirical data. The gradient of understanding power map
  (middle) shows a red hot spot in the top left highlighting the
  region where the best mechanistic understanding occur. The
  predicting-understanding power map (bottom) shows the sum of the two
  previous maps highlighting a red hot spot where the best synthesis
  research joining predicting and understanding power of the empirical
  data might occur. The first research goal of this proposal aims to
  build an automated research platform to maximize the predicting and
  understanding power highlighted in the red hot spot of the
  predicting-understanding power map (bottom).}
