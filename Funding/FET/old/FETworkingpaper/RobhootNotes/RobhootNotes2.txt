Deep Knowledge Ledger Network :: 
DEEPKLEN ROBHOOT
================================

Features -------------
Multilayer automation

DL KG automation

DLT ledger

Open Decentralized Secure Fast?

Decentralized Knowledge-public data inspired technology

End-to-end encryption ::
automatic sensor network and public data to report generation
----------------------

State-of-art and beyond --------

A. The science ecosystem :: taking decisions about limited resources and trusting/untrusting peers
Current design :: centralized bias error-prone

Arquitecture design peer-to-peer network with a mixture of trusted-untrusted peers missing 

Error prone multiple steps cycle where reproducibility is a key factor -- multiple stages that need recording to keep peers and public decisions updated 

B. Digital ecosystem
A blockchain can be defined as an immutable ledger for recording transactions, maintained within a distributed hybrid network of mutually
trusting/trusting peers. Every peer maintains a copy of the ledger. The peers execute a consensus protocol to validate transactions, group them into blocks, and build a hash chain over the blocks. This process forms the ledger by ordering the transactions, as is neces-
sary for consistency. Blockchains have emerged with Bitcoin [3] and are widely regarded as a promising technology to run trusted
exchanges of information in the digital world.

C. Fabric 
The architecture of Fabric follows a novel execute-order-validate paradigm for distributed execution of untrusted code in an untrusted environment. It separates the transaction flow into three steps, which may be run on different entities in the system: (1) executing a transaction and checking its correctness, thereby endorsing it (corresponding to “transaction validation” in other blockchains);
(2) ordering through a consensus protocol, irrespective of transaction semantics; and (3) transaction validation per application-specific trust assumptions, which also prevents race conditions due to concurrency.

D. Report AI USA
General intelligence ------- prediction ::
Yet, we are still only working in narrow models. The Roadmap envisions new hybrid 
modeling approaches that could be facilitated via advanced AI learning research. Advancements 
in machine-learning techniques will enable techniques to process multi-modal, multi-scale data, 
handle heterogeneity in space and time, and accurately quantify uncertainty in the results. The 
report imagines in vignette 3.3.2.3 that these hybrid models could allow development of highly 
accurate flood maps that would save many lives in future hurricanes. Developments in this area 
would enable better living through more accurate forecasting and predicting for natural disasters. 
The continued improvement of AI systems will impact the pillars of science, from 
observation to experiment to discovery. Vignette 3.2.2.2 describes how a future system might 
help a team discover new materials that meet certain properties by using its ability to mine the 
available literature looking for new novel approaches, articulate hypotheses, and design 
experiments, all while helping facilitate communications and collaborative interactions between 
all the scientists involved. These developments will rapidly increase the pace of discovery and 
innovation, and will prove to be a substantial competitive advantage to the countries engaged.

E. From TON whitepaper
 2.1 Blockchain implementation
 
 2.6.25. Decentralization of the system. One might suspect that a Proof-of-Stake system such as the TON Blockchain, relying on T ≈ 1000 validators to create all shardchain and masterchain blocks, is bound to become “too
centralized”, as opposed to conventional Proof-of-Work blockchains like Bit-
coin or Ethereum, where everybody (in principle) might mine a new block, without an explicit upper limit on the total number of miners.
However, popular Proof-of-Work blockchains, such as Bitcoin and Ethereum, currently require vast amounts of computing power (high “hash rates”)
to mine new blocks with non-negligible probability of success. Thus, the mining of new blocks tends to be concentrated in the hands of several large players, who invest huge amounts money into datacenters filled with custom-
designed hardware optimized for mining; and in the hands of several large mining pools, which concentrate and coordinate the efforts of larger groups of people who are not able to provide a sufficient “hash rate” by themselves.
Therefore, as of 2017, more than 75% of new Ethereum or Bitcoin blocks are produced by less than ten miners. In fact, the two largest Ethereum mining pools produce together more than half of all new blocks! Clearly,
such a system is much more centralized than one relying on T ≈ 1000 nodes to produce new blocks. One might also note that the investment required to become a TON Blockchain validator—i.e., to buy the hardware (say, several high-performance
servers) and the stake (which can be easily collected through a pool of nominators if necessary; cf. 2.6.3)—is much lower than that required to become a successful stand-alone Bitcoin or Ethereum miner. In fact, the parame-
ter L of 2.6.7 will force nominators not to join the largest “mining pool” (i.e., the validator that has amassed the largest stake), but rather to look for smaller validators currently accepting funds from nominators, or even to
create new validators, because this would allow a higher proportion s0i/si of
the validator’s—and by extension also the nominator’s—stake to be used,
hence yielding larger rewards from mining. In this way, the TON Proof-of-Stake system actually encourages decentralization (creating and using more validators) and punishes centralization.
-----------------

F. Decentralized prediction markets
 2009, Almenberg, Kittlitz and Pfeiffer conducted a series of experiments in which they demonstrated the ability of PMs to accelerate scientific research. In the modern scientific community, communication is slow and similar tasks are sometimes investigated by independent groups that are not aware of each other’s results. However, it turned out that PMs between them, even without the sharing of information, allowed for the engagements as a single omniscient group, which was able to quickly identify the most realistic hypotheses among the many possible

-------------------

References ------------------------------------
DLT :: Golem IOTATangled TON x

Neural networks :: Dimensions Learning (Luisño)

Multilayer networks :: each layer different agents :: multilayer? heterarchy?

Data science with encripted data :: name?
-----------------------------------------------

Repository :: 
Robhoot to c4science

TEAM --------------
Christine SDSC
Raul 
Victor
Roger Guimera :: meet :: Mallorca JAN end 2020?

Partners:
Charles 
Benoit?
Inca -- Evgeny?
Eawag -- Harald: send draft
-------------------

0. Acronym ::
Dec Open Auto Res Network
DOARNET DAREN 

Robhoot open automated research networks
RON
ROAR
ROARNES

4r + decentralization

Centralization :: 
On one side many platforms focus on specific layers of the scientific process, sensor networks, data processing, inference or visualization. On the other hand, decentralized science platforms (scienceroot) aims to enhance peer-to-peer technology to minimize...  
 
4. Make clear how Robhoot differs from ARP

Decentralized:: editorial(publisher)-review-submissions:
check literature ::  scienceroot partner :: Distributed Ledger Technology (DLT)

Multiple layer integration :: end-to-end

multiple layer <--> Renku <--> notebook 

Victor :: task flow diagram ::

Data processing
https://news.bitcoin.com/pr-plan-flash-decentralized-data-processing/

5. Open::
Most Automated projects driven by the industry:: see table

--------------------

6. Milestones

Dashboard as README file


Layers
311 Data processing >> integration 
(Ali Charles Harald)

312 Complexity reduction 
313 Inference
Probabilistic ML or deep learning in Bayesian neural networks

314 Validation
315 Visualization 
316 Reporting :: notebook
317 DLT :: notebook >> Blockchain 
    
Biodiversity research testnet case study

Golem network?
Data sensors
Data public 
Notebook
Accessibility
Scalability 


7. Figures

Triangle data-rule-knowledge tradeoffs
Refs rules

What is the difference between rule and knowledge?

  -- short term -- polynomials 
  -- medium-long term -- dynamic equations 



----- From here ------------

6. Additional database
NEON LTEN
Rat experiment -- mysql
David birds communication
Bern paper -- database 
===========================

=====================
ASK A QUESTION

How many jobs in science? Open market access
Plot network applicants-committees (strategies?)
Where am i with my algo? Open trees access

-------------------


PROCESS===========
------------
OCT 8 2018
Animation-Visualization 5 layers: 
Makie-Tikz combi
------------
OCT 22 2018 working paper
Build ref doc bib
------------
NOV 12 2018
database David -- sounds
Intro -- data driven vs theory driven
Sections -- bib + general ideas
Pseudocode 
------------
NOV 19 2018
Figure 1 -- tikz-networks
------------
NOV 26 2018
Writing draft -- 
Many problems do not require mechanistic theories -- games (refs). However, other kind of problems would require a more mechanistic understanding -- how to accurately discern human driven from background climate change?


test tikz julia - refs -- 
gaps: scalability -- account uncertainty
Detailed code -- whiteboard
Example 
==================

SECTIONS----------
DATA ADQUISITION and INTEGRATION
DaaDI

Writing ------
Data integration -- standarization 
Size effects: N labs (or sites) vs N sampling per lab -- Accuracy -- uncertainty -- 
How do initial distributions change accuracy and uncertainty? Trade-offs experimental vs big data? --> check paper

DIMENSIONALITY REDUCTION
PCA family
Convex hull + Ellipse 
Information multilayer networks

-------
Charles-Oskar GitHub -- repo -- 
Generalizing complexity reduction models
GoCORE
-------

PROCESS PATTERN INFERENCE
PROPENCE 

Metrics 
aggregation-dispersion-correlation
Markov random fields -- AI book
Process -- IBM -- ABM -- PBM: Uncertainty-

VALIDATION
VATION

Uncertainty-Sensitivity-Robustness
Information criteria -- AICc BICc
ABC -- Bayes Factors: adaptive-non adaptive alg
Gibbs sampling

VISUALIZATION
VITION

Jove
Plotly Falcon
Automated plotting -- julia package: tikz --
Check tikz-network in julia




